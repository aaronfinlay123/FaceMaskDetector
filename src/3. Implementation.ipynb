{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "After the model has been trained, it is now ready to be put into practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model\n",
    "\n",
    "In order for to use the trained model, it must first be loaded into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedmodel = load_model('model-050.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting faces using the Haar Cascade Classifier\n",
    "A CNN was used in the training phase to detect faces while the model is being trained. In the implemntation phase, it is a lot faster and easier to just use the Haar Cascade Classifiers for detecting the frontal facial features of a user. While this is okay to be used in the implementation phase, it should be used in the training process as it tends to be inaccurate when additional variables are introduced such as faces from a side profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceclassifier=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the webcam for the implementation\n",
    "The implementation of the model that is being used here will take each frame from a users webcam and then resize and reshape it, similar to how that was done to every image in the dataset in the preprocessing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcamera=cv2.VideoCapture(0)\n",
    "\n",
    "labels={0:'NO MASK',1:'MASK'}\n",
    "colours={0:(0,0,255),1:(0,255,0)}\n",
    "\n",
    "while(True):\n",
    "    ret,frame=webcamera.read()\n",
    "    grey=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=faceclassifier.detectMultiScale(grey,1.3,5)\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        face=grey[y:y+w,x:x+w]\n",
    "        resized=cv2.resize(face,(100,100))\n",
    "        normalised=resized/255.0\n",
    "        reshaped=np.reshape(normalised,(1,100,100,1))\n",
    "        result=trainedmodel.predict(reshaped)\n",
    "\n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),colours[label],2)\n",
    "        cv2.rectangle(frame,(x,y-40),(x+w,y),colours[label],-1)\n",
    "        cv2.putText(frame, labels[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "        \n",
    "    cv2.imshow('Face mask detector by Kyle Hennessy, Jordan Marah, Aaron Finlay',frame)\n",
    "    key=cv2.waitKey(1)\n",
    "    \n",
    "    #if the key press is \"escape\" then we break out of the loop and close the window\n",
    "    if(key==27):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "webcamera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
